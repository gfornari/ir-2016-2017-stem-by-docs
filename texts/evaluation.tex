\section{Evaluation}
We evaluated using TerrierCITAZIONE with three different configuration, in order to figure out if SNS improves the effectiveness of the overall system. In particular, we evaluated Terrier without stemmer, Terrier with SnowBallCITAZIONE stemmer and Terrier with SNS. In all experiments, we did not remove the stopwords and we used bm25 as ranking model. We evaluated using the following methrics:

\begin{itemize}
\item MAP (Mean Average Precision), defined as the average on all topics of the AP (Average Precision) calculated on the single topic:
\begin{equation}
MAP(R) = \frac{\sum_{t \in T}AP(r_t)}{|T|}
\end{equation}
where AP is defined as:
\begin{equation}
AP(r_t)=\frac{1}{RB_t}\sum_{k=1}^{N}\widetilde{r_t}[k]\frac{\sum_{h=1}^{k}\widetilde{r_t}[h]}{k}
\end{equation}

\item Prec@10, defined as the number of relevant documents retrieved with rank between $[1, 10]$ divided by 10.

\item R-Prec (Precision at Recall Base), defined as the number of relevant documents retrieved with rank between $[1,RB_t]$ divided by the recall base of the topic;

\item F-Measure, that combines precision and recall. Considering that the use of a stemmer can affect these methrics, we thought that a resume of both of them can be explanatory of the behaviour of the system. F-Measure is defined as $1 - (E-Measure)$ where E-Measure is:
\begin{equation}
E-Measure=\frac{|D^{*}\cup D|-|D^{*}\cap D|}{|D^{*}\cup D|}
\end{equation}
$D^{*}$: relevant documents

$D$: retrieved documents

\end{itemize}

We list the results for Russian in Table \ref{tab:ruEval}, for Italian in Table \ref{tab:itEval} and for German in Table \ref{tab:deEval}. We highligth in bold the better result and in italic the worse result for every methric, in every corpus.

\begin{center}
   \begin{tabular}{| l | l | l | l |}
    \hline
    \multicolumn{4}{|l|}{\textbf{Russian}}\\ \hline
    & No Stem & SnowBall & SNS\\ \hline
    MAP & \textit{0.3012} & \textbf{0.4666} & 0.4245 \\ \hline
    Prec@10 & \textit{0.1821} & \textbf{0.2607}  & 0.2464 \\ \hline
    R-Prec & \textit{0.2646} & \textbf{0.3981} & 0.3768\\ \hline
    F-Measure & \textbf{0.0386} & 0.0205 & \textit{0.0190}\\ \hline    
    \end{tabular}
    \captionof{table}{Comparison using Terrier with bm25 of SNS, SnowBall and no stemming, for the Russian corpus.}
    \label{tab:ruEval}
\end{center}

With Russian (Table \ref{tab:ruEval}), there is a great benefit using a stemmer in MAP, Prec@10 and R-Prec. Instead, F-Measure decrease with SnowBall and SNS. Furthermore, SnowBall works better than SNS in every methric. 

\begin{center}
   \begin{tabular}{| l | l | l | l |}
    \hline
    \multicolumn{4}{|l|}{\textbf{Italian}}\\ \hline
    & No Stem & SnowBall & SNS\\ \hline
    MAP & 0.3482 & \textbf{0.3887} & \textit{0.3059} \\ \hline
    Prec@10 & \textit{0.2529} & \textbf{0.2824} & 0.2549 \\ \hline
    R-Prec & \textbf{0.3365} & 0.3616 & \textit{0.3063}\\ \hline
    F-Measure & \textbf{0.0331} & 0.0308 & \textit{0.0267} \\ \hline    
    \end{tabular}
    \captionof{table}{Comparison using Terrier with bm25 of SNS, SnowBall and no stemming, for the Italian corpus.}
    \label{tab:itEval}
\end{center}

Using the Italian corpus (Table \ref{tab:itEval}), the situation is more complex. MAP increases using SnowBall, but decreases using SNS. Prec@10 increases using a stemmer, in particular using SnowBall. Lastly, F-Measure decreases a bit using SnowBall, but there is a great drop with SNS.

\begin{center}
   \begin{tabular}{| l | l | l | l |}
    \hline
    \multicolumn{4}{|l|}{\textbf{German}}\\ \hline
    & No Stem & SnowBall & SNS\\ \hline
    MAP & 0.1459 & \textbf{0.1667} & \textit{0.1257} \\ \hline
    Prec@10 & 0.2304 & \textbf{0.2679} & \textit{0.1893} \\ \hline
    R-Prec & 0.1680 & \textbf{0.1934} & \textit{0.1502}\\ \hline
    F-Measure & 0.0318 & \textbf{0.0326} & \textit{0.0239}\\ \hline    
    \end{tabular}
    \captionof{table}{Comparison using Terrier with bm25 of SNS, SnowBall and no stemming, for the German corpus.}
    \label{tab:deEval}
\end{center}

With the German corpus (Table \ref{tab:deEval}), SNS works badly. While SnowBall improves all the methrics, SNS worsens every one of them. 

The better performance of SnowBall compared to SNS is not surprising, considering that SNS is designed to be language independent while SnowBall has ad-hoc version for every one of the tested languages. However, the results show how SNS does not improve the effectiveness of the retrieval with every corpus. SNS can be a good choice with a Russian corpus, or, depending on the context, with the Italian: considering the drop in F-Measure and MAP, but the increase of Prec@10, it can work well in context where it is primary the retrieve of relevant document in the first positions. Instead, the results shows how SNS worsens the effectiveness of the system with a German corpus. 

\subsection{Strength}
The bad performance with the German corpus may be caused by the complexity of the language: a statistical stemmer can have more difficulties to manage it in a general and independent way. For this reason, we choosed to further analyze the producted stems in order to find some clues in this direction.

There are two kinds of errors that can occur during stemming:

\begin{itemize}
\item \textbf{under-stemming}: the resultant stem is longer compared to the correct stem of the word;
\item \textbf{over-stemming}: the resultant stem is shorter compared to the correct stem of the word.
\end{itemize}

Under-stemming and over-stemming errors are related to stemmer stength, i.e., the degree to which a stemmer changes words that it stems. Stemmer strength is discussed in Frakes, Fox, 2003\cite{frakes} and in Sirsat, Chavan, Mahalle, 2013\cite{sirsat}.
A weak stemmer is one that handles few suffixes and merges only highly related words, and it is more prone to under-stemming errors.
On the other hand, a strong stemmer handles more suffixes and merges wide variety of forms, but it may be subject to over-stemming errors. Strength of stemmer is important because it can be predective of recall and precision: on average, a stronger stemmer tends to increase recall and decrease precision.
Over-stemming or under-stemming are errors in the calculation of the stem, but this not necessarily means that they are a problem for the stemmer itself: according to the consideration about the relation of these errors to recall and precision, the developer should choose the appropriate stemmer to the context. 

Frakes and Fox have proposed some measure to evaluate the strength of a stemmer. Between these, they suggested the mean modified Hamming distance (mmHd). The Hamming distance of two strings of equal length is the number of characters that differs in the same position; the modified Hamming distance is the Hamming distance plus the difference in lenght of the two strings. The mean modified Hamming distance, then, is the average of the modified Hamming distance for each pairs word-stem.

We computed this methric using the Italian, Russian and German corpora with our stemmer and SnowBall stemmer. We list the results on Table \ref{tab:strength}.

\begin{center}
   \begin{tabular}{| l | l | l | l |}
    \hline
    & \multicolumn{3}{l|}{\textbf{Mean Modified Hamming Distance}}\\ \hline
    Stemmer & Italian & Russian & German\\ \hline
    SNS & 1.75 & 1.88 & 3.31 \\ \hline
    SnowBall & 1.70 & 1.80 & 1.64\\ \hline    
    \end{tabular}
    \captionof{table}{Evaluation of SNS and Snowball strength, using mean modified Hamming distance.}
    \label{tab:strength}
\end{center}

Based on these measures, we found that SNS is a little heavier than SnowBall in the Italian and Russian corpora, and it is considerably stronger than SnowBall in the German corpus. Furthermore, the mmHd for German with SNS differs greatly from the rest. We deepened this result with an analysis of the stems length. In particular, we found that the average length of the stems does not differ too much from one language to another. Instead, the average length of the terms that will be stem using SNS varies greatly: from a minimum of 8.84 characters for the Italian to a maximum of 12.28 characters for the German. Therefore, SNS removes more characters in German compared to other languages, and this may increase the risk of over-stemming. We list this results on Table \ref{tab:length}.

\begin{center}
   \begin{tabular}{| l | l | l | l | l |}
    \hline
    & Italian & Russian & German\\ \hline
    Original word length & 8.84 & 10.00 & 12.28\\ \hline
    Stem length & 3.76 & 4.71 & 3.94\\ \hline   
    Removed Characters & 5.08 & 5.29 &  8.34\\ \hline
    \end{tabular}
    \captionof{table}{Comparison between length of words stemmed by SNS, the length of the respectively stems and the number of removed characters from the original word to the stem. Every measure is an average on the set of words with a stem that differ from the original word.}
    \label{tab:length}
\end{center}

This result suggests that SNS may stems better for some languages and worse for others. If this is the case, the worse performance of the stemmer with the German corpus can be partly caused by over-stemming errors, that may decrease the precision of the overall system. 