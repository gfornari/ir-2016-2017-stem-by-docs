\section{Evaluation}
We evaluated Terrier\cite{terrier} with three different configurations, in order to figure out if SNS improves the effectiveness of the overall system. In particular, we evaluated Terrier without stemmer, Terrier with Snowball\cite{snowball} stemmer and Terrier with SNS. In all experiments, we did not remove the stop words and we used BM25 as ranking model. We evaluated using the following metrics:

\begin{itemize}
\item \emph{AP} (Average Precision), defined as:
\begin{equation}
AP(r_t)=\frac{1}{RB_t}\sum_{k=1}^{N}\widetilde{r_t}[k]\frac{\sum_{h=1}^{k}\widetilde{r_t}[h]}{k}
\end{equation}

\item \emph{Prec@10}, defined as the number of relevant documents retrieved with rank between $[1, 10]$ divided by 10.

\item \emph{R-Prec} (Precision at Recall Base), defined as the number of relevant documents retrieved with rank between $[1,|RB_t|]$ divided by the recall base of the topic;

%\item \emph{F-Measure}, that combines precision and recall. Considering that the use of a stemmer can affect these metrics, we thought that a resume of both of them can be explanatory of the behaviour of the system. F-Measure is defined as $1 - (E\textnormal{-}Measure)$ where E-Measure is:
%\begin{equation}
%E\textnormal{-}Measure=\frac{|D^{*}\cup D|-|D^{*}\cap D|}{|D^{*}\cup D|}
%\end{equation}

%$D^{*}$: relevant documents

%$D$: retrieved documents

\end{itemize}

We measured the average of every measure for each topic. For example, we considered \emph{MAP} (Mean Average Precision), defined as the average of the AP of each topic.

We list the results for Russian in Table \ref{tab:ruEval}, for Italian in Table \ref{tab:itEval} and for German in Table \ref{tab:deEval}. We highlight in bold the best results and in italic the worst results for each metric in every corpus. Furthemore, we list the number of relevant documents retrieved.

\begin{center}
   \begin{tabular}{| l | l | l | l |}
    \hline
    \multicolumn{4}{|l|}{\textbf{Russian (151 relevant docs)}}\\ \hline
    & No Stem & Snowball & SNS\\ \hline
    MAP & \textit{0.3012} & \textbf{0.4666} & 0.4245 \\ \hline
    Prec@10 & \textit{0.1821} & \textbf{0.2607}  & 0.2464 \\ \hline
    R-Prec & \textit{0.2646} & \textbf{0.3981} & 0.3768\\ \hline
    %F-Measure & \textbf{0.0386} & 0.0205 & \textit{0.0190}\\ \hline
    N. Relevant Retrieved & \textit{119} & \textbf{143} & \textbf{143}\\ \hline    
    \end{tabular}
    \captionof{table}{Comparison using Terrier with BM25 of SNS, Snowball and no stemming for the Russian corpus.}
    \label{tab:ruEval}
\end{center}

With Russian (Table \ref{tab:ruEval}), there is a great benefit using a stemmer in MAP, Prec@10 and R-Prec; however, precision with Snowball is better compared to SNS. Snowball and SNS increase also the number of relevant documents retrieved. 

\begin{center}
   \begin{tabular}{| l | l | l | l |}
    \hline
    \multicolumn{4}{|l|}{\textbf{Italian (809 relevant docs)}}\\ \hline
    & No Stem & Snowball & SNS\\ \hline
    MAP & 0.3482 & \textbf{0.3887} & \textit{0.3059} \\ \hline
    Prec@10 & \textit{0.2529} & \textbf{0.2824} & 0.2549 \\ \hline
    R-Prec & 0.3365 & \textbf{0.3616} & \textit{0.3063}\\ \hline
    %F-Measure & \textbf{0.0331} & 0.0308 & \textit{0.0267} \\ \hline    
	N. Relevant Retrieved & 723 & \textbf{746} & \textit{709}\\ \hline        
    \end{tabular}
    \captionof{table}{Comparison using Terrier with BM25 of SNS, Snowball and no stemming for the Italian corpus.}
    \label{tab:itEval}
\end{center}

Using the Italian corpus (Table \ref{tab:itEval}), the situation is more complex. MAP, R-Prec and recall increase using Snowball, but decrease using SNS. Prec@10 increases using a stemmer, in particular using Snowball. 

\begin{center}
   \begin{tabular}{| l | l | l | l |}
    \hline
    \multicolumn{4}{|l|}{\textbf{German (1825 relevant docs)}}\\ \hline
    & No Stem & Snowball & SNS\\ \hline
    MAP & 0.1459 & \textbf{0.1667} & \textit{0.1257} \\ \hline
    Prec@10 & 0.2304 & \textbf{0.2679} & \textit{0.1893} \\ \hline
    R-Prec & 0.1680 & \textbf{0.1934} & \textit{0.1502}\\ \hline
    %F-Measure & 0.0318 & \textbf{0.0326} & \textit{0.0239}\\ \hline    
	N. Relevant Retrieved & \textit{534} & \textbf{601} & 538\\ \hline        
    \end{tabular}
    \captionof{table}{Comparison using Terrier with BM25 of SNS, Snowball and no stemming for the German corpus.}
    \label{tab:deEval}
\end{center}

With the German corpus (Table \ref{tab:deEval}), SNS works badly. While Snowball improves all the metrics, SNS worsens every one of them. Only the number of relevant documents retrieved increases a little using SNS, but Snowball performs even better.

The better performance of Snowball compared to SNS is not surprising, considering that SNS is designed to be language independent while Snowball has ad-hoc version for each tested language. However, the results show how SNS does not improve the effectiveness of the retrieval with every corpus. SNS can be a good choice with a Russian corpus, or, depending on the context, with the Italian: considering the drop in MAP, but the increase of Prec@10, it can work well in a context where it is primary the retrieval of relevant documents in top positions. Instead, the results show how SNS worsens the effectiveness of the system with a German corpus. 

\subsection{Strength}
The bad performance with the German corpus may be caused by the complexity of the language; a statistical stemmer can have more difficulties to manage it in a general and independent way. For this reason, we chose to further analyse the stems produced in order to find some clues in this direction.

Two kinds of errors can occur during stemming:

\begin{itemize}
\item \textbf{under-stemming}: the resultant stem is longer compared to the correct stem of the word;
\item \textbf{over-stemming}: the resultant stem is shorter compared to the correct stem of the word.
\end{itemize}

Under-stemming and over-stemming errors are related to stemmer strength, i.e., the degree to which a stemmer changes words that it stems. Stemmer strength is discussed in Frakes, Fox, 2003\cite{frakes} and in Sirsat, Chavan, Mahalle, 2013\cite{sirsat}. A weak stemmer is one that handles few suffixes and merges only highly related words, and it is more prone to under-stemming errors. On the other hand, a strong stemmer handles more suffixes and merges wide variety of forms, but it may be subject to over-stemming errors. Strength of stemmer is important because it can be
predictive of recall and precision: on average, a stronger stemmer tends to increase recall and decrease precision. Over-stemming and under-stemming are errors in the calculation of the stem, but this not necessarily means that they are a problem for the stemmer itself. According to the consideration about the relation of these errors to recall and precision, the developer should choose the appropriate stemmer to the context. 

Frakes and Fox have proposed some measures to evaluate the strength of a stemmer. Between these, they suggested the \emph{mean modified Hamming distance} (mmHd). The Hamming distance of two strings of equal length is the number of characters that differs in the same position; the modified Hamming distance is the Hamming distance plus the difference in length of the two strings. The mean modified Hamming distance, then, is the average of the modified Hamming distance for each pairs word-stem.

We computed this metric using the Italian, Russian and German corpora with SNS and Snowball stemmers. We list the results on Table \ref{tab:strength}.

\begin{center}
   \begin{tabular}{| l | l | l | l |}
    \hline
    & \multicolumn{3}{l|}{\textbf{Mean Modified Hamming Distance}}\\ \hline
    Stemmer & Italian & Russian & German\\ \hline
    SNS & 1.75 & 1.88 & 3.31 \\ \hline
    Snowball & 1.70 & 1.80 & 1.64\\ \hline    
    \end{tabular}
    \captionof{table}{Evaluation of SNS and Snowball strength, using mean modified Hamming distance.}
    \label{tab:strength}
\end{center}

Based on these measures, we found that SNS is a little heavier than Snowball in the Italian and Russian corpora, and it is considerably stronger than Snowball in the German corpus. Furthermore, the mmHd for German with SNS differs greatly from the rest. We deepened this result with an analysis of the stems length. In particular, we found that the average length of the stems does not differ too much from one language to another. Instead, the average length of the terms stemmed using SNS varies widely: from a minimum of 8.84 characters for the Italian to a maximum of 12.28 characters for the German. Therefore, SNS removes more characters in German compared to other languages, and this may increase the risk of over-stemming. We list these results on Table \ref{tab:length}.

\begin{center}
   \begin{tabular}{| l | l | l | l | l |}
    \hline
    & Italian & Russian & German\\ \hline
    Original word length & 8.84 & 10.00 & 12.28\\ \hline
    Stem length & 3.76 & 4.71 & 3.94\\ \hline   
    Removed Characters & 5.08 & 5.29 &  8.34\\ \hline
    \end{tabular}
    \captionof{table}{Comparison between length of words stemmed by SNS, the length of the respectively stems and the number of removed characters from the original word to the stem. Every measure is an average on the set of words with a stem that differ from the original word.}
    \label{tab:length}
\end{center}

This result suggests that SNS may stems better for some languages and worse for others. If this is the case, the worse performance of the stemmer with the German corpus can be partly caused by over-stemming errors, which may decrease the precision of the overall system.