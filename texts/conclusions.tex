\section{Conclusions}
The original paper\cite{sns} explains in detail the logic behind SNS. There are two ambiguity: the choice of the stems from the clusters and the choice of the multiplicative factor in the recalculation of the co-occurences strength.

While the logic is clear, the authors did not refer about difficulties on the implementation of the algorithm. The main problem occured during the implementation was the amount of primary memory needed for the co-occurence matrix. As a result of this, efficiency becomes primary: it is mandatory to choose a smart data structure, in order to optimize the memory consumption and the operations on data. We managed this using an external library for sparse matrix, that allows multithreaded operations on data.

Compared to Terrier without stemming, SNS generally improves the effectiveness on retrieval with Italian and Russian. However, Snowball (a language-specific stemmer) worked better in each test. Instead, with a German corpus we had better performance using Terrier without stemmer. SNS stems heavier with German, compared to other languages: this can be the cause of over-stemming errors. This result may suggests that SNS works good with some languages, and not with others.  